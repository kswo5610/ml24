{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 11 – Training Deep Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 11._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml3/blob/main/11_training_deep_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml3/blob/main/11_training_deep_neural_networks.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project requires Python 3.7 or above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And TensorFlow ≥ 2.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in previous chapters, let's define the default font sizes to make the figures prettier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's create the `images/deep` folder (if it doesn't already exist), and define the `save_fig()` function which is used through this notebook to save the figures in high-res for the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"deep\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Glorot initialization and He initialization were designed to make the output standard deviation as close as possible to the input standard deviation, at least at the beginning of training. This reduces the vanishing/exploding gradients problem.\n",
    "2. No, all weights should be sampled independently; they should not all have the same initial value. One important goal of sampling weights randomly is to break symmetry: if all the weights have the same initial value, even if that value is not zero, then symmetry is not broken (i.e., all neurons in a given layer are equivalent), and backpropagation will be unable to break it. Concretely, this means that all the neurons in any given layer will always have the same weights. It's like having just one neuron per layer, and much slower. It is virtually impossible for such a configuration to converge to a good solution.\n",
    "3. It is perfectly fine to initialize the bias terms to zero. Some people like to initialize them just like weights, and that's OK too; it does not make much difference.\n",
    "4. ReLU is usually a good default for the hidden layers, as it is fast and yields good results. Its ability to output precisely zero can also be useful in some cases (e.g., see Chapter 17). Moreover, it can sometimes benefit from optimized implementations as well as from hardware acceleration. The leaky ReLU variants of ReLU can improve the model's quality without hindering its speed too much compared to ReLU. For large neural nets and more complex problems, GLU, Swish and Mish can give you a slightly higher quality model, but they have a computational cost. The hyperbolic tangent (tanh) can be useful in the output layer if you need to output a number in a fixed range (by default between –1 and 1), but nowadays it is not used much in hidden layers, except in recurrent nets. The sigmoid activation function is also useful in the output layer when you need to estimate a probability (e.g., for binary classification), but it is rarely used in hidden layers (there are exceptions—for example, for the coding layer of variational autoencoders; see Chapter 17). The softplus activation function is useful in the output layer when you need to ensure that the output will always be positive. The softmax activation function is useful in the output layer to estimate probabilities for mutually exclusive classes, but it is rarely (if ever) used in hidden layers.\n",
    "5. If you set the `momentum` hyperparameter too close to 1 (e.g., 0.99999) when using an `SGD` optimizer, then the algorithm will likely pick up a lot of speed, hopefully moving roughly toward the global minimum, but its momentum will carry it right past the minimum. Then it will slow down and come back, accelerate again, overshoot again, and so on. It may oscillate this way many times before converging, so overall it will take much longer to converge than with a smaller `momentum` value.\n",
    "6. One way to produce a sparse model (i.e., with most weights equal to zero) is to train the model normally, then zero out tiny weights. For more sparsity, you can apply ℓ<sub>1</sub> regularization during training, which pushes the optimizer toward sparsity. A third option is to use the TensorFlow Model Optimization Toolkit.\n",
    "7. Yes, dropout does slow down training, in general roughly by a factor of two. However, it has no impact on inference speed since it is only turned on during training. MC Dropout is exactly like dropout during training, but it is still active during inference, so each inference is slowed down slightly. More importantly, when using MC Dropout you generally want to run inference 10 times or more to get better predictions. This means that making predictions is slowed down by a factor of 10 or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deep Learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the Swish activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    activation=\"swish\",\n",
    "                                    kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `tf.keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the output layer to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a Nadam optimizer with a learning rate of 5e-5. I tried learning rates 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3 and 1e-2, and I compared their learning curves for 10 epochs each (using the TensorBoard callback, below). The learning rates 3e-5 and 1e-4 were pretty good, so I tried 5e-5, which turned out to be slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let's use the first 5,000 images of the original training set as the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the callbacks we need and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model\",\n",
    "                                                         save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1057f894e5c958e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1057f894e5c958e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1397/1407 [============================>.] - ETA: 0s - loss: 4.3223 - accuracy: 0.1637INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 11s 6ms/step - loss: 4.3079 - accuracy: 0.1638 - val_loss: 2.1531 - val_accuracy: 0.2270\n",
      "Epoch 2/100\n",
      "1395/1407 [============================>.] - ETA: 0s - loss: 2.0756 - accuracy: 0.2403INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 5ms/step - loss: 2.0749 - accuracy: 0.2405 - val_loss: 2.1077 - val_accuracy: 0.2314\n",
      "Epoch 3/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.9695 - accuracy: 0.2777INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.9694 - accuracy: 0.2777 - val_loss: 1.9378 - val_accuracy: 0.2924\n",
      "Epoch 4/100\n",
      "1396/1407 [============================>.] - ETA: 0s - loss: 1.8971 - accuracy: 0.3093INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.8972 - accuracy: 0.3095 - val_loss: 1.8708 - val_accuracy: 0.3238\n",
      "Epoch 5/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.8341 - accuracy: 0.3328INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.8339 - accuracy: 0.3328 - val_loss: 1.7938 - val_accuracy: 0.3408\n",
      "Epoch 6/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.7774 - accuracy: 0.3558INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.7773 - accuracy: 0.3560 - val_loss: 1.7406 - val_accuracy: 0.3650\n",
      "Epoch 7/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.7343 - accuracy: 0.3726INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7343 - accuracy: 0.3726 - val_loss: 1.7364 - val_accuracy: 0.3644\n",
      "Epoch 8/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.6922 - accuracy: 0.3903INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6920 - accuracy: 0.3903 - val_loss: 1.6817 - val_accuracy: 0.3932\n",
      "Epoch 9/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.6580 - accuracy: 0.4027INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6580 - accuracy: 0.4027 - val_loss: 1.6572 - val_accuracy: 0.4004\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.6374 - accuracy: 0.4098 - val_loss: 1.6992 - val_accuracy: 0.3810\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.6116 - accuracy: 0.4208 - val_loss: 1.6913 - val_accuracy: 0.3862\n",
      "Epoch 12/100\n",
      " 311/1407 [=====>........................] - ETA: 3s - loss: 1.5993 - accuracy: 0.4199"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5062 - accuracy: 0.4676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5061508417129517, 0.4675999879837036]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the lowest validation loss gets about 46.8% accuracy on the validation set. It took 29 epochs to reach the lowest validation loss, with roughly 10 seconds per epoch on my laptop (without a GPU). Let's see if we can improve the model using Batch Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "*Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is very similar to the code above, with a few changes:\n",
    "\n",
    "* I added a BN layer after every Dense layer (before the activation function), except for the output layer.\n",
    "* I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.\n",
    "* I renamed the run directories to run_bn_* and the model file name to `my_cifar10_bn_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 2.0377 - accuracy: 0.2523INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 32s 18ms/step - loss: 2.0374 - accuracy: 0.2525 - val_loss: 1.8766 - val_accuracy: 0.3154\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7874 - accuracy: 0.3542 - val_loss: 1.8784 - val_accuracy: 0.3268\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 20s 15ms/step - loss: 1.6806 - accuracy: 0.3969 - val_loss: 1.9764 - val_accuracy: 0.3252\n",
      "Epoch 4/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.6111 - accuracy: 0.4229INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.6112 - accuracy: 0.4228 - val_loss: 1.7087 - val_accuracy: 0.3750\n",
      "Epoch 5/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.5520 - accuracy: 0.4478INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5521 - accuracy: 0.4476 - val_loss: 1.6272 - val_accuracy: 0.4176\n",
      "Epoch 6/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5030 - accuracy: 0.4659INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.5030 - accuracy: 0.4660 - val_loss: 1.5401 - val_accuracy: 0.4452\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4559 - accuracy: 0.4812 - val_loss: 1.6990 - val_accuracy: 0.3952\n",
      "Epoch 8/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.4169 - accuracy: 0.4987INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4168 - accuracy: 0.4987 - val_loss: 1.5078 - val_accuracy: 0.4652\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3863 - accuracy: 0.5123 - val_loss: 1.5513 - val_accuracy: 0.4470\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3514 - accuracy: 0.5216 - val_loss: 1.5208 - val_accuracy: 0.4562\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3220 - accuracy: 0.5314 - val_loss: 1.7301 - val_accuracy: 0.4206\n",
      "Epoch 12/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.2933 - accuracy: 0.5410INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.2931 - accuracy: 0.5410 - val_loss: 1.4909 - val_accuracy: 0.4734\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2702 - accuracy: 0.5490 - val_loss: 1.5256 - val_accuracy: 0.4636\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2424 - accuracy: 0.5591 - val_loss: 1.5569 - val_accuracy: 0.4624\n",
      "Epoch 15/100\n",
      "<<12 more lines>>\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1174 - accuracy: 0.6066 - val_loss: 1.5241 - val_accuracy: 0.4828\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0978 - accuracy: 0.6128 - val_loss: 1.5313 - val_accuracy: 0.4772\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0844 - accuracy: 0.6198 - val_loss: 1.4993 - val_accuracy: 0.4924\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0677 - accuracy: 0.6244 - val_loss: 1.4622 - val_accuracy: 0.5078\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0571 - accuracy: 0.6297 - val_loss: 1.4917 - val_accuracy: 0.4990\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.0395 - accuracy: 0.6327 - val_loss: 1.4888 - val_accuracy: 0.4896\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0298 - accuracy: 0.6370 - val_loss: 1.5358 - val_accuracy: 0.5024\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0150 - accuracy: 0.6444 - val_loss: 1.5219 - val_accuracy: 0.5030\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0100 - accuracy: 0.6456 - val_loss: 1.4933 - val_accuracy: 0.5098\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9956 - accuracy: 0.6492 - val_loss: 1.4756 - val_accuracy: 0.5012\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9787 - accuracy: 0.6576 - val_loss: 1.5181 - val_accuracy: 0.4936\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9710 - accuracy: 0.6565 - val_loss: 1.7510 - val_accuracy: 0.4568\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9613 - accuracy: 0.6628 - val_loss: 1.5576 - val_accuracy: 0.4910\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.9530 - accuracy: 0.6651 - val_loss: 1.5087 - val_accuracy: 0.5046\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 0.9388 - accuracy: 0.6701 - val_loss: 1.5534 - val_accuracy: 0.4950\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9331 - accuracy: 0.6743 - val_loss: 1.5033 - val_accuracy: 0.5046\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.9144 - accuracy: 0.6808 - val_loss: 1.5679 - val_accuracy: 0.5028\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4236 - accuracy: 0.5074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4236289262771606, 0.5073999762535095]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(\"swish\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model\",\n",
    "                                                         save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_bn_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Is the model converging faster than before?* Much faster! The previous model took 29 epochs to reach the lowest validation loss, while the new model achieved that same loss in just 12 epochs and continued to make progress until the 17th epoch. The BN layers stabilized training and allowed us to use a much larger learning rate, so convergence was faster.\n",
    "* *Does BN produce a better model?* Yes! The final model is also much better, with 50.7% validation accuracy instead of 46.7%. It's still not a very good model, but at least it's much better than before (a Convolutional Neural Network would do much better, but that's a different topic, see chapter 14).\n",
    "* *How does BN affect training speed?* Although the model converged much faster, each epoch took about 15s instead of 10s, because of the extra computations required by the BN layers. But overall the training time (wall time) to reach the best model was shortened by about 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.9386 - accuracy: 0.3045INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 20s 13ms/step - loss: 1.9385 - accuracy: 0.3046 - val_loss: 1.8175 - val_accuracy: 0.3510\n",
      "Epoch 2/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.7241 - accuracy: 0.3869INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.7241 - accuracy: 0.3869 - val_loss: 1.7677 - val_accuracy: 0.3614\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.6272 - accuracy: 0.4263INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6272 - accuracy: 0.4263 - val_loss: 1.6878 - val_accuracy: 0.4054\n",
      "Epoch 4/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5644 - accuracy: 0.4492INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5643 - accuracy: 0.4492 - val_loss: 1.6589 - val_accuracy: 0.4304\n",
      "Epoch 5/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.5080 - accuracy: 0.4712INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5080 - accuracy: 0.4712 - val_loss: 1.5651 - val_accuracy: 0.4538\n",
      "Epoch 6/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.4611 - accuracy: 0.4873INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4613 - accuracy: 0.4872 - val_loss: 1.5305 - val_accuracy: 0.4678\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4174 - accuracy: 0.5077 - val_loss: 1.5346 - val_accuracy: 0.4558\n",
      "Epoch 8/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.3781 - accuracy: 0.5175INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3781 - accuracy: 0.5175 - val_loss: 1.4773 - val_accuracy: 0.4882\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3413 - accuracy: 0.5345 - val_loss: 1.5021 - val_accuracy: 0.4764\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.3182 - accuracy: 0.5422 - val_loss: 1.5709 - val_accuracy: 0.4762\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2832 - accuracy: 0.5571 - val_loss: 1.5345 - val_accuracy: 0.4868\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2557 - accuracy: 0.5667 - val_loss: 1.5024 - val_accuracy: 0.4900\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2373 - accuracy: 0.5710 - val_loss: 1.5114 - val_accuracy: 0.5028\n",
      "Epoch 14/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.2071 - accuracy: 0.5846INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2073 - accuracy: 0.5847 - val_loss: 1.4608 - val_accuracy: 0.5026\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1843 - accuracy: 0.5940 - val_loss: 1.4962 - val_accuracy: 0.5038\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1617 - accuracy: 0.6026 - val_loss: 1.5255 - val_accuracy: 0.5062\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1452 - accuracy: 0.6084 - val_loss: 1.5057 - val_accuracy: 0.5036\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1297 - accuracy: 0.6145 - val_loss: 1.5097 - val_accuracy: 0.5010\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1004 - accuracy: 0.6245 - val_loss: 1.5218 - val_accuracy: 0.5014\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0971 - accuracy: 0.6304 - val_loss: 1.5253 - val_accuracy: 0.5090\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0670 - accuracy: 0.6345 - val_loss: 1.5006 - val_accuracy: 0.5034\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0544 - accuracy: 0.6407 - val_loss: 1.5244 - val_accuracy: 0.5010\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0338 - accuracy: 0.6502 - val_loss: 1.5355 - val_accuracy: 0.5096\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0281 - accuracy: 0.6514 - val_loss: 1.5257 - val_accuracy: 0.5164\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4097 - accuracy: 0.6478 - val_loss: 1.8203 - val_accuracy: 0.3514\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3733 - accuracy: 0.5157 - val_loss: 1.5600 - val_accuracy: 0.4664\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2032 - accuracy: 0.5814 - val_loss: 1.5367 - val_accuracy: 0.4944\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1291 - accuracy: 0.6121 - val_loss: 1.5333 - val_accuracy: 0.4852\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0734 - accuracy: 0.6317 - val_loss: 1.5475 - val_accuracy: 0.5032\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0294 - accuracy: 0.6469 - val_loss: 1.5400 - val_accuracy: 0.5052\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0081 - accuracy: 0.6605 - val_loss: 1.5617 - val_accuracy: 0.4856\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0109 - accuracy: 0.6603 - val_loss: 1.5727 - val_accuracy: 0.5124\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9646 - accuracy: 0.6762 - val_loss: 1.5333 - val_accuracy: 0.5174\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9597 - accuracy: 0.6789 - val_loss: 1.5601 - val_accuracy: 0.5016\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4608 - accuracy: 0.5026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4607702493667603, 0.5026000142097473]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_selu_model\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_selu_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model reached the first model's validation loss in just 8 epochs. After 14 epochs, it reached its lowest validation loss, with about 50.3% accuracy, which is better than the original model (46.7%), but not quite as good as the model using batch normalization (50.7%). Each epoch took only 9 seconds. So it's the fastest model to train so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "*Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.8953 - accuracy: 0.3240INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 18s 11ms/step - loss: 1.8950 - accuracy: 0.3239 - val_loss: 1.7556 - val_accuracy: 0.3812\n",
      "Epoch 2/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.6618 - accuracy: 0.4129INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.6618 - accuracy: 0.4130 - val_loss: 1.6563 - val_accuracy: 0.4114\n",
      "Epoch 3/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.5772 - accuracy: 0.4431INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5770 - accuracy: 0.4432 - val_loss: 1.6507 - val_accuracy: 0.4232\n",
      "Epoch 4/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5081 - accuracy: 0.4673INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.5081 - accuracy: 0.4672 - val_loss: 1.5892 - val_accuracy: 0.4566\n",
      "Epoch 5/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.4560 - accuracy: 0.4902INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4561 - accuracy: 0.4902 - val_loss: 1.5382 - val_accuracy: 0.4696\n",
      "Epoch 6/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.4095 - accuracy: 0.5050INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4094 - accuracy: 0.5050 - val_loss: 1.5236 - val_accuracy: 0.4818\n",
      "Epoch 7/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.3634 - accuracy: 0.5234INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3636 - accuracy: 0.5232 - val_loss: 1.5139 - val_accuracy: 0.4840\n",
      "Epoch 8/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.3297 - accuracy: 0.5377INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3296 - accuracy: 0.5378 - val_loss: 1.4780 - val_accuracy: 0.4982\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2907 - accuracy: 0.5485 - val_loss: 1.5151 - val_accuracy: 0.4854\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.2559 - accuracy: 0.5646 - val_loss: 1.4980 - val_accuracy: 0.4976\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2221 - accuracy: 0.5767 - val_loss: 1.5199 - val_accuracy: 0.4990\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1960 - accuracy: 0.5870 - val_loss: 1.5167 - val_accuracy: 0.5030\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1684 - accuracy: 0.5955 - val_loss: 1.5815 - val_accuracy: 0.5014\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1463 - accuracy: 0.6025 - val_loss: 1.5427 - val_accuracy: 0.5112\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1125 - accuracy: 0.6169 - val_loss: 1.5868 - val_accuracy: 0.5212\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0854 - accuracy: 0.6243 - val_loss: 1.6234 - val_accuracy: 0.5090\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0668 - accuracy: 0.6328 - val_loss: 1.6162 - val_accuracy: 0.5072\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0440 - accuracy: 0.6442 - val_loss: 1.5748 - val_accuracy: 0.5162\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0272 - accuracy: 0.6477 - val_loss: 1.6518 - val_accuracy: 0.5200\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.0007 - accuracy: 0.6594 - val_loss: 1.6224 - val_accuracy: 0.5186\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9824 - accuracy: 0.6639 - val_loss: 1.6972 - val_accuracy: 0.5136\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9660 - accuracy: 0.6714 - val_loss: 1.7210 - val_accuracy: 0.5278\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 0.9472 - accuracy: 0.6780 - val_loss: 1.6436 - val_accuracy: 0.5006\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9314 - accuracy: 0.6819 - val_loss: 1.7059 - val_accuracy: 0.5160\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9172 - accuracy: 0.6888 - val_loss: 1.6926 - val_accuracy: 0.5200\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8990 - accuracy: 0.6947 - val_loss: 1.7705 - val_accuracy: 0.5148\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8758 - accuracy: 0.7028 - val_loss: 1.7023 - val_accuracy: 0.5198\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8622 - accuracy: 0.7090 - val_loss: 1.7567 - val_accuracy: 0.5184\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4780 - accuracy: 0.4982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4779616594314575, 0.498199999332428]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_alpha_dropout_model\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_alpha_dropout_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model reaches 48.1% accuracy on the validation set. That's worse than without dropout (50.3%). With an extensive hyperparameter search, it might be possible to do better (I tried dropout rates of 5%, 10%, 20% and 40%, and learning rates 1e-4, 3e-4, 5e-4, and 1e-3), but probably not much better in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use MC Dropout now. We will need the `MCAlphaDropout` class we used earlier, so let's just copy it here for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(tf.keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a new model, identical to the one we just trained (with the same weights), but with `MCAlphaDropout` dropout layers instead of `AlphaDropout` layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = tf.keras.Sequential([\n",
    "    (\n",
    "        MCAlphaDropout(layer.rate)\n",
    "        if isinstance(layer, tf.keras.layers.AlphaDropout)\n",
    "        else layer\n",
    "    )\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return Y_probas.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make predictions for all the instances in the validation set, and compute the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4984"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = (y_pred == y_valid[:, 0]).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get back to roughly the accuracy of the model without dropout in this case (about 50.3% accuracy).\n",
    "\n",
    "So the best model we got in this exercise is the Batch Normalization model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f.\n",
    "*Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 3s 8ms/step - loss: nan - accuracy: 0.1706\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1,\n",
    "                                   batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=2e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.0559 - accuracy: 0.2839 - val_loss: 1.7917 - val_accuracy: 0.3768\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.7596 - accuracy: 0.3797 - val_loss: 1.6566 - val_accuracy: 0.4258\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.6199 - accuracy: 0.4247 - val_loss: 1.6395 - val_accuracy: 0.4260\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.5451 - accuracy: 0.4524 - val_loss: 1.6202 - val_accuracy: 0.4408\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.4952 - accuracy: 0.4691 - val_loss: 1.5981 - val_accuracy: 0.4488\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4541 - accuracy: 0.4842 - val_loss: 1.5720 - val_accuracy: 0.4490\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4171 - accuracy: 0.4967 - val_loss: 1.6035 - val_accuracy: 0.4470\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.3497 - accuracy: 0.5194 - val_loss: 1.4918 - val_accuracy: 0.4864\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2788 - accuracy: 0.5459 - val_loss: 1.5597 - val_accuracy: 0.4672\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2070 - accuracy: 0.5707 - val_loss: 1.5845 - val_accuracy: 0.4864\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.1433 - accuracy: 0.5926 - val_loss: 1.5293 - val_accuracy: 0.4998\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0745 - accuracy: 0.6182 - val_loss: 1.5118 - val_accuracy: 0.5072\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.0030 - accuracy: 0.6413 - val_loss: 1.5388 - val_accuracy: 0.5204\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.9388 - accuracy: 0.6654 - val_loss: 1.5547 - val_accuracy: 0.5210\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.8989 - accuracy: 0.6805 - val_loss: 1.5835 - val_accuracy: 0.5242\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "n_iterations = math.ceil(len(X_train_scaled) / batch_size) * n_epochs\n",
    "onecycle = OneCycleScheduler(n_iterations, max_lr=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One cycle allowed us to train the model in just 15 epochs, each taking only 2 seconds (thanks to the larger batch size). This is several times faster than the fastest model we trained so far. Moreover, we improved the model's performance (from 50.7% to 52.0%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
